{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Object detection_kk",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "N6ZDpd9XzFeN",
        "vlA3CftFpRiW"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N6ZDpd9XzFeN"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "KUu4vOt5zI9d",
        "colab": {}
      },
      "source": [
        "# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CxmDMK4yupqg"
      },
      "source": [
        "# Object detection\n",
        "\n",
        "<table align=\"left\"><td>\n",
        "  <a target=\"_blank\"  href=\"https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/object_detection.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab\n",
        "  </a>\n",
        "</td><td>\n",
        "  <a target=\"_blank\"  href=\"https://github.com/tensorflow/hub/blob/master/examples/colab/object_detection.ipynb\">\n",
        "    <img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "</td></table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Sy553YSVmYiK"
      },
      "source": [
        "This Colab demonstrates use of a TF-Hub module trained to perform object detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v4XGxDrCkeip"
      },
      "source": [
        "## Imports and function definitions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "6cPY9Ou4sWs_",
        "colab": {}
      },
      "source": [
        "#@title Imports and function definitions\n",
        "\n",
        "# Currently %tensorflow_version 2.x installs beta1, which doesn't work here.\n",
        "# %tensorflow_version can likely be used after 2.0rc0  \n",
        "!pip install tf-nightly-gpu-2.0-preview\n",
        "\n",
        "# For running inference on the TF-Hub module.\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# For downloading the image.\n",
        "import matplotlib.pyplot as plt\n",
        "import tempfile\n",
        "from six.moves.urllib.request import urlopen\n",
        "from six import BytesIO\n",
        "\n",
        "# For drawing onto the image.\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from PIL import ImageColor\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageOps\n",
        "\n",
        "# For measuring the inference time.\n",
        "import time\n",
        "\n",
        "# Check available GPU devices.\n",
        "print(\"The following GPU devices are available: %s\" % tf.test.gpu_device_name())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZGkrXGy62409"
      },
      "source": [
        "## Example use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vlA3CftFpRiW"
      },
      "source": [
        "### Helper functions for downloading images and for visualization.\n",
        "\n",
        "Visualization code adapted from [TF object detection API](https://github.com/tensorflow/models/blob/master/research/object_detection/utils/visualization_utils.py) for the simplest required functionality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D9IwDpOtpIHW",
        "colab": {}
      },
      "source": [
        "def display_image(image):\n",
        "  fig = plt.figure(figsize=(20, 15))\n",
        "  plt.grid(False)\n",
        "  plt.imshow(image)\n",
        "\n",
        "\n",
        "def download_and_resize_image(url, new_width=256, new_height=256,\n",
        "                              display=False):\n",
        "  _, filename = tempfile.mkstemp(suffix=\".jpg\")\n",
        "  response = urlopen(url)\n",
        "  image_data = response.read()\n",
        "  image_data = BytesIO(image_data)\n",
        "  pil_image = Image.open(image_data)\n",
        "  pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n",
        "  pil_image_rgb = pil_image.convert(\"RGB\")\n",
        "  pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n",
        "  print(\"Image downloaded to %s.\" % filename)\n",
        "  if display:\n",
        "    display_image(pil_image)\n",
        "  return filename\n",
        "\n",
        "\n",
        "def draw_bounding_box_on_image(image,\n",
        "                               ymin,\n",
        "                               xmin,\n",
        "                               ymax,\n",
        "                               xmax,\n",
        "                               color,\n",
        "                               font,\n",
        "                               thickness=4,\n",
        "                               display_str_list=()):\n",
        "  \"\"\"Adds a bounding box to an image.\"\"\"\n",
        "  draw = ImageDraw.Draw(image)\n",
        "  im_width, im_height = image.size\n",
        "  (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
        "                                ymin * im_height, ymax * im_height)\n",
        "  draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n",
        "             (left, top)],\n",
        "            width=thickness,\n",
        "            fill=color)\n",
        "\n",
        "  # If the total height of the display strings added to the top of the bounding\n",
        "  # box exceeds the top of the image, stack the strings below the bounding box\n",
        "  # instead of above.\n",
        "  display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
        "  # Each display_str has a top and bottom margin of 0.05x.\n",
        "  total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
        "\n",
        "  if top > total_display_str_height:\n",
        "    text_bottom = top\n",
        "  else:\n",
        "    text_bottom = bottom + total_display_str_height\n",
        "  # Reverse list and print from bottom to top.\n",
        "  for display_str in display_str_list[::-1]:\n",
        "    text_width, text_height = font.getsize(display_str)\n",
        "    margin = np.ceil(0.05 * text_height)\n",
        "    draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n",
        "                    (left + text_width, text_bottom)],\n",
        "                   fill=color)\n",
        "    draw.text((left + margin, text_bottom - text_height - margin),\n",
        "              display_str,\n",
        "              fill=\"black\",\n",
        "              font=font)\n",
        "    text_bottom -= text_height - 2 * margin\n",
        "\n",
        "\n",
        "def draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.1):\n",
        "  \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n",
        "  colors = list(ImageColor.colormap.values())\n",
        "\n",
        "  try:\n",
        "    font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\",\n",
        "                              25)\n",
        "  except IOError:\n",
        "    print(\"Font not found, using default font.\")\n",
        "    font = ImageFont.load_default()\n",
        "\n",
        "  for i in range(min(boxes.shape[0], max_boxes)):\n",
        "    if scores[i] >= min_score:\n",
        "      ymin, xmin, ymax, xmax = tuple(boxes[i])\n",
        "      display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"),\n",
        "                                     int(100 * scores[i]))\n",
        "      color = colors[hash(class_names[i]) % len(colors)]\n",
        "      image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n",
        "      draw_bounding_box_on_image(\n",
        "          image_pil,\n",
        "          ymin,\n",
        "          xmin,\n",
        "          ymax,\n",
        "          xmax,\n",
        "          color,\n",
        "          font,\n",
        "          display_str_list=[display_str])\n",
        "      np.copyto(image, np.array(image_pil))\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D19UCu9Q2-_8"
      },
      "source": [
        "## Apply module\n",
        "\n",
        "Load a public image from Open Images v4, save locally, and display."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "YLWNhjUY1mhg",
        "colab": {}
      },
      "source": [
        "image_url = \"https://farm1.staticflickr.com/4032/4653948754_c0d768086b_o.jpg\"  #@param\n",
        "downloaded_image_path = download_and_resize_image(image_url, 1280, 856, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t-VdfLbC1w51"
      },
      "source": [
        "Pick an object detection module and apply on the downloaded image. Modules:\n",
        "* **FasterRCNN+InceptionResNet V2**: high accuracy,\n",
        "* **ssd+mobilenet V2**: small and fast."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uazJ5ASc2_QE",
        "colab": {}
      },
      "source": [
        "module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\" #@param [\"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\", \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"]\n",
        "\n",
        "detector = hub.load(module_handle).signatures['default']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "znW8Fq1EC0x7",
        "colab": {}
      },
      "source": [
        "def load_img(path):\n",
        "  img = tf.io.read_file(path)\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kwGJV96WWBLH",
        "colab": {}
      },
      "source": [
        "def run_detector(detector, path):\n",
        "  img = load_img(path)\n",
        "\n",
        "  converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
        "  start_time = time.time()\n",
        "  result = detector(converted_img)\n",
        "  end_time = time.time()\n",
        "\n",
        "  result = {key:value.numpy() for key,value in result.items()}\n",
        "\n",
        "  print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n",
        "  print(\"Inference time: \", end_time-start_time)\n",
        "\n",
        "  image_with_boxes = draw_boxes(\n",
        "      img.numpy(), result[\"detection_boxes\"],\n",
        "      result[\"detection_class_entities\"], result[\"detection_scores\"])\n",
        "\n",
        "  display_image(image_with_boxes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vchaUW1XDodD",
        "colab": {}
      },
      "source": [
        "run_detector(detector, downloaded_image_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WUUY3nfRX7VF"
      },
      "source": [
        "### More images\n",
        "Perform inference on some additional images with time tracking.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rubdr2JXfsa1",
        "colab": {}
      },
      "source": [
        "image_urls = [\"https://farm7.staticflickr.com/8092/8592917784_4759d3088b_o.jpg\",\n",
        "              \"https://farm6.staticflickr.com/2598/4138342721_06f6e177f3_o.jpg\",\n",
        "              \"https://c4.staticflickr.com/9/8322/8053836633_6dc507f090_o.jpg\"]\n",
        "\n",
        "for image_url in image_urls:\n",
        "  start_time = time.time()\n",
        "  image_path = download_and_resize_image(image_url, 640, 480)\n",
        "  run_detector(detector, image_path)\n",
        "  end_time = time.time()\n",
        "  print(\"Inference time:\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz_l1nV7_d2l",
        "colab_type": "text"
      },
      "source": [
        "# custom pipline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8JhOUPqgTaM",
        "colab_type": "text"
      },
      "source": [
        "[detection-model](https://www.dlology.com/blog/how-to-train-an-object-detection-model-easy-for-free/)\n",
        "\n",
        "[objdet_train_tensorflow_colab](https://github.com/RomRoc/objdet_train_tensorflow_colab/blob/master/objdet_custom_tf_colab.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL26xrhZfThX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14GfpA8mfUPG",
        "colab_type": "text"
      },
      "source": [
        "[](https://github.com/RomRoc/objdet_train_tensorflow_colab/blob/master/objdet_custom_tf_colab.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlEqsyJY_KTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install Cython\n",
        "!pip install jupyter\n",
        "!pip install matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJu_cnV2FcTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd\n",
        "# !pip install tensorflow-gpu==1.14\n",
        "  \n",
        "# !git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "# !apt-get install -qq protobuf-compiler python-tk\n",
        "\n",
        "# !pip install -q Cython contextlib2 pillow lxml matplotlib PyDrive\n",
        "\n",
        "# !pip install -q pycocotools\n",
        "\n",
        "%cd ~/models/research\n",
        "# !protoc object_detection/protos/*.proto --python_out=.\n",
        "# !protoc object_detection/protos/anchor_generator.proto --python_out=.\n",
        "# !protoc -I=./ --python_out=./ ./object_detection/protos/*.proto\n",
        "# !wget -O protobuf.zip https://github.com/google/protobuf/releases/download/v3.0.0/protoc-3.0.0-linux-x86_64.zip\n",
        "# !unzip protobuf.zip\n",
        "# !protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "!./bin/protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/root/models/research/:/root/models/research/slim/'\n",
        "\n",
        "# %cd ~/models/research/\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cVzW0CsGHVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBMpJQY5LBqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5mPtwlmPcB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBCs1dxOPb63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TME4cvZ5PXAd",
        "colab_type": "text"
      },
      "source": [
        "# Run inference\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvGJOASsLvlb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd ~/models/research/object_detection\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "if tf.__version__ < '1.4.0':\n",
        "  raise ImportError('Please upgrade your tensorflow installation to v1.4.* or later!')\n",
        "  \n",
        "\n",
        "  \n",
        "  \n",
        "# This is needed to display the images.\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from utils import label_map_util\n",
        "\n",
        "from utils import visualization_utils as vis_util\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# What model to download.\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT = '/content/datalab/fine_tuned_model' + '/frozen_inference_graph.pb'\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = os.path.join('/content/datalab', 'label_map.pbtxt')\n",
        "\n",
        "NUM_CLASSES = 37\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
        "PATH_TO_TEST_IMAGES_DIR = '/content/datalab/'\n",
        "TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image{}.jpg'.format(i)) for i in range(1, 2) ]\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def run_inference_for_single_image(image, graph):\n",
        "  with graph.as_default():\n",
        "    with tf.Session() as sess:\n",
        "      # Get handles to input and output tensors\n",
        "      ops = tf.get_default_graph().get_operations()\n",
        "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "      tensor_dict = {}\n",
        "      for key in [\n",
        "          'num_detections', 'detection_boxes', 'detection_scores',\n",
        "          'detection_classes', 'detection_masks'\n",
        "      ]:\n",
        "        tensor_name = key + ':0'\n",
        "        if tensor_name in all_tensor_names:\n",
        "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "              tensor_name)\n",
        "      if 'detection_masks' in tensor_dict:\n",
        "        # The following processing is only for single image\n",
        "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
        "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
        "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
        "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
        "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
        "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "        detection_masks_reframed = tf.cast(\n",
        "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "        # Follow the convention by adding back the batch dimension\n",
        "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "            detection_masks_reframed, 0)\n",
        "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "      # Run inference\n",
        "      output_dict = sess.run(tensor_dict,\n",
        "                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
        "      output_dict['detection_classes'] = output_dict[\n",
        "          'detection_classes'][0].astype(np.uint8)\n",
        "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "      if 'detection_masks' in output_dict:\n",
        "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "  return output_dict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for image_path in TEST_IMAGE_PATHS:\n",
        "  image = Image.open(image_path)\n",
        "  # the array based representation of the image will be used later in order to prepare the\n",
        "  # result image with boxes and labels on it.\n",
        "  image_np = load_image_into_numpy_array(image)\n",
        "  # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "  image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "  # Actual detection.\n",
        "  output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "  # Visualization of the results of a detection.\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks'),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=8)\n",
        "  plt.figure(figsize=IMAGE_SIZE)\n",
        "  plt.imshow(image_np)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEpXIzxwfEkj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NxYSsGtNGlI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Hi:\n",
        "\n",
        "\tI remember a post several days ago by Jon Baron, concerning the\n",
        "behavior of sum() when one sets na.rm=TRUE:\n",
        "the result will be a zero sum for a vector of all NA's, as here, for the\n",
        "second row:\n",
        "\n",
        "> ss<- data.frame(x=c(1,NA,3,4),y=c(2,NA,4,NA))\n",
        "> ss\n",
        "   x  y\n",
        "1  1  2\n",
        "2 NA NA\n",
        "3  3  4\n",
        "4  4 NA\n",
        "\n",
        "> apply(ss,1,sum,na.rm=TRUE)\n",
        "1 2 3 4 \n",
        "3 0 7 4 \n",
        "\n",
        "I am rather alarmed by that zero, because I was just about to place the sum\n",
        "function into am apply() on a rather large data management project, where\n",
        "about 5% of my matrix rows have two missing values.  Is there a \"safe\" way\n",
        "to use sum(), so that such zeroes are not created?  A safe.sum() that takes\n",
        "arguments just as general as sum()?  I mean, I think I could get around this\n",
        "little problem like this,\n",
        "\n",
        "apply(ss,1,function(x){ifelse(all(is.na(x)),NA,sum(!is.na(x))*mean(x,na.rm=T\n",
        "RUE))})\n",
        " 1  2  3  4 \n",
        " 3 NA  7  4 \n",
        "\n",
        "but is there a safer way to write a sum() function?  Or, do these zeroes\n",
        "serve some purpose that I am missing?\n",
        "Thanks in advance..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfnAZgtIt3VF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tmp <- ddply(filter(master_subset, SNPSH_DT == CLSD_DT &\n",
        " SNPSH_DT != 0 &\n",
        " SNPSH_DT < (TT+1)), ~ SNPSH_DT, function(x) {\n",
        " x[is.na(x$DEAL_SIZE)==TRUE]=0;\n",
        " sum(x$DEAL_SIZE,na.rm=TRUE)\n",
        " })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_OETsGDGTNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Yhux_TNGIPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def function(x):\n",
        "    if x['DEAL_SIZE'] == True:\n",
        "        \n",
        "temp = master_subset[(master_subset['SNPSH_DT']=='CLSD_DT') & (master_subset['SNPSH_DT']!=0) & (master_subset['SNPSH_DT']< TT+1)].apply(lambda x: finction(x), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0woT3QOTGSUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "temp = master_subset[(master_subset['SNPSH_DT']==CLSD_DT) & (master_subset['SNPSH_DT']!=0) & (master_subset['SNPSH_DT']< TT+1)]\n",
        "temp = temp[temp['SNPSH_DT']==False]\n",
        "# temp = temp['DEAL_SIZE'].replace('N.A', 0)\n",
        "temp = temp[temp['DEAL_SIZE']].fillna(value=0)\n",
        "temp_sum = temp[['DEAL_SIZE']].sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDRPA4ienYIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNLvrEVQsanE",
        "colab_type": "text"
      },
      "source": [
        "[keras-ocr](https://github.com/faustomorales/keras-ocr)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtlpBb91nYGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To install from master\n",
        "!pip install git+https://github.com/faustomorales/keras-ocr.git#egg=keras-ocr\n",
        "\n",
        "# To install from PyPi\n",
        "!pip install keras-ocr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RjCSXkXnYDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Get a set of three example images\n",
        "# glob.glob(f\"{img_dir}*{e}\") for e in [\".jpg\", '.png']\n",
        "\n",
        "# print(prediction_groups)\n",
        "# Plot the predictions\n",
        "fig, axs = plt.subplots(nrows=len(images), figsize=(40, 40))\n",
        "for ax, image, predictions in zip(axs, images, prediction_groups):\n",
        "    keras_ocr.tools.drawAnnotations(image=image, predictions=predictions, ax=ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScuH-FuiteSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_dir = \"/content/\"\n",
        "imput_img_dir = [glob.glob(f\"{img_dir}*{e}\") for e in ['.jpg', '.png']][0]\n",
        "print(imput_img_dir)\n",
        "# glob.glob('/content/*.jpg')\n",
        "images = [keras_ocr.tools.read(url) for url in imput_img_dir]\n",
        "\n",
        "# Each list of predictions in prediction_groups is a list of\n",
        "# (word, box) tuples.\n",
        "\n",
        "prediction_groups = pipeline.recognize(images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftITKQeKvJ2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DThXjMZxnX40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY66_4KM-TgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def drow_rectangle_box(img_array, xmin_ymin, xmax_ymax):\n",
        "    image = np.copy(img_array)\n",
        "    for a, b in zip(xmin_ymin, xmax_ymax):\n",
        "        image = cv2.rectangle(image,a,b,[0,255,2],2)\n",
        "    return image\n",
        "\n",
        "\n",
        "def convert_poins(prediction_groups):\n",
        "    xmin_ymin = []\n",
        "    xmax_ymax = []\n",
        "    for multi_pt in prediction_groups:\n",
        "        for single_pt in multi_pt:\n",
        "            xmin_ymin.append(tuple(single_pt[1][0]))\n",
        "            xmax_ymax.append(tuple(single_pt[1][2]))\n",
        "    return xmin_ymin ,xmax_ymax\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TlsIYPRHdE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prediction_groups[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4DetiNjAmP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for inx, img_path in enumerate(imput_img_dir):\n",
        "    a, b= convert_poins([prediction_groups[inx]])\n",
        "    img = cv2.imread(img_path)\n",
        "    img = drow_rectangle_box(img ,a, b)\n",
        "\n",
        "    plt.figure(figsize=(30, 30))\n",
        "    plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggLCLCOngvks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuJCv3U9gvho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTEmfl3Mgvb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29KxaiTu8Hnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "img1 = cv2.imread(\"query.jpeg\",0) # queryImage\n",
        "img2 = cv2.imread(\"train.jpeg\",0) # trainImage\n",
        "\n",
        "\n",
        "# Initiate ORB detector\n",
        "\n",
        "orb = cv2.ORB_create()\n",
        "\n",
        "# find the keypoints and descriptors with ORB\n",
        "\n",
        "kp1, des1 = orb.detectAndCompute(img1,None)\n",
        "kp2, des2 = orb.detectAndCompute(img2,None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haAFQ77ygwET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_kp = cv2.drawKeypoints(img2, kp2, 0, color=(0,255,0), flags=0)\n",
        "plt.imshow(img_kp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5ZGsRJhg0PH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv2.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBSvVsqdkTaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install opencv-python==3.1.0.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgLGUN7MkbiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}