{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tranceferlearning(ResNet18/34).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtJjFYamuUb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSwFhqIFOAWO",
        "colab_type": "text"
      },
      "source": [
        "# ResNet34 or ResNet18 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksUWSm8WWPim",
        "colab_type": "text"
      },
      "source": [
        "[pretrained-resnet34-in-keras](https://www.kaggle.com/meaninglesslives/pretrained-resnet34-in-keras)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4O_Jbp3PPsh8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "e5bfb189-a2e6-42dc-a818-d1606dcaea97"
      },
      "source": [
        "import keras.backend as K\n",
        "from keras.layers import Input\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Activation\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import ZeroPadding2D\n",
        "from keras.layers import Dense, Add\n",
        "from keras.models import Model\n",
        "from keras.engine import get_source_inputs\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "import keras\n",
        "from distutils.version import StrictVersion\n",
        "\n",
        "if StrictVersion(keras.__version__) < StrictVersion('2.2.0'):\n",
        "    from keras.applications.imagenet_utils import _obtain_input_shape\n",
        "else:\n",
        "    from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "\n",
        "def build_resnet(\n",
        "     repetitions=(2, 2, 2, 2),\n",
        "     include_top=True,\n",
        "     input_tensor=None,\n",
        "     input_shape=None,\n",
        "     classes=1000,\n",
        "     block_type='usual'):\n",
        "\n",
        "    # Determine proper input shape\n",
        "    input_shape = _obtain_input_shape(input_shape,\n",
        "                                      default_size=224,\n",
        "                                      min_size=32,\n",
        "                                      data_format='channels_last',\n",
        "                                      require_flatten=include_top)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = Input(shape=input_shape, name='data')\n",
        "    else:\n",
        "        if not K.is_keras_tensor(input_tensor):\n",
        "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "    \n",
        "    # get parameters for model layers\n",
        "    no_scale_bn_params = get_bn_params(scale=False)\n",
        "    bn_params = get_bn_params()\n",
        "    conv_params = get_conv_params()\n",
        "    init_filters = 64\n",
        "\n",
        "    if block_type == 'basic':\n",
        "        conv_block = basic_conv_block\n",
        "        identity_block = basic_identity_block\n",
        "    else:\n",
        "        conv_block = usual_conv_block\n",
        "        identity_block = usual_identity_block\n",
        "    \n",
        "    # resnet bottom\n",
        "    x = BatchNormalization(name='bn_data', **no_scale_bn_params)(img_input)\n",
        "    x = ZeroPadding2D(padding=(3, 3))(x)\n",
        "    x = Conv2D(init_filters, (7, 7), strides=(2, 2), name='conv0', **conv_params)(x)\n",
        "    x = BatchNormalization(name='bn0', **bn_params)(x)\n",
        "    x = Activation('relu', name='relu0')(x)\n",
        "    x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='valid', name='pooling0')(x)\n",
        "    \n",
        "    # resnet body\n",
        "    for stage, rep in enumerate(repetitions):\n",
        "        for block in range(rep):\n",
        "            \n",
        "            filters = init_filters * (2**stage)\n",
        "            \n",
        "            # first block of first stage without strides because we have maxpooling before\n",
        "            if block == 0 and stage == 0:\n",
        "                x = conv_block(filters, stage, block, strides=(1, 1))(x)\n",
        "                \n",
        "            elif block == 0:\n",
        "                x = conv_block(filters, stage, block, strides=(2, 2))(x)\n",
        "                \n",
        "            else:\n",
        "                x = identity_block(filters, stage, block)(x)\n",
        "                \n",
        "    x = BatchNormalization(name='bn1', **bn_params)(x)\n",
        "    x = Activation('relu', name='relu1')(x)\n",
        "\n",
        "    # resnet top\n",
        "    if include_top:\n",
        "        x = GlobalAveragePooling2D(name='pool1')(x)\n",
        "        x = Dense(classes, name='fc1')(x)\n",
        "        x = Activation('softmax', name='softmax')(x)\n",
        "\n",
        "    # Ensure that the model takes into account any potential predecessors of `input_tensor`.\n",
        "    if input_tensor is not None:\n",
        "        inputs = get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "        \n",
        "    # Create model.\n",
        "    model = Model(inputs, x)\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10slDblLV3T7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpQwmuAiTOle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def handle_block_names(stage, block):\n",
        "    name_base = 'stage{}_unit{}_'.format(stage + 1, block + 1)\n",
        "    conv_name = name_base + 'conv'\n",
        "    bn_name = name_base + 'bn'\n",
        "    relu_name = name_base + 'relu'\n",
        "    sc_name = name_base + 'sc'\n",
        "    return conv_name, bn_name, relu_name, sc_name\n",
        "\n",
        "\n",
        "def basic_identity_block(filters, stage, block):\n",
        "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
        "    # Arguments\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    \"\"\"\n",
        "\n",
        "    def layer(input_tensor):\n",
        "        conv_params = get_conv_params()\n",
        "        bn_params = get_bn_params()\n",
        "        conv_name, bn_name, relu_name, sc_name = handle_block_names(stage, block)\n",
        "\n",
        "        x = BatchNormalization(name=bn_name + '1', **bn_params)(input_tensor)\n",
        "        x = Activation('relu', name=relu_name + '1')(x)\n",
        "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "        x = Conv2D(filters, (3, 3), name=conv_name + '1', **conv_params)(x)\n",
        "\n",
        "        x = BatchNormalization(name=bn_name + '2', **bn_params)(x)\n",
        "        x = Activation('relu', name=relu_name + '2')(x)\n",
        "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "        x = Conv2D(filters, (3, 3), name=conv_name + '2', **conv_params)(x)\n",
        "\n",
        "        x = Add()([x, input_tensor])\n",
        "        return x\n",
        "\n",
        "    return layer\n",
        "\n",
        "\n",
        "def basic_conv_block(filters, stage, block, strides=(2, 2)):\n",
        "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    \"\"\"\n",
        "\n",
        "    def layer(input_tensor):\n",
        "        conv_params = get_conv_params()\n",
        "        bn_params = get_bn_params()\n",
        "        conv_name, bn_name, relu_name, sc_name = handle_block_names(stage, block)\n",
        "\n",
        "        x = BatchNormalization(name=bn_name + '1', **bn_params)(input_tensor)\n",
        "        x = Activation('relu', name=relu_name + '1')(x)\n",
        "        shortcut = x\n",
        "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "        x = Conv2D(filters, (3, 3), strides=strides, name=conv_name + '1', **conv_params)(x)\n",
        "\n",
        "        x = BatchNormalization(name=bn_name + '2', **bn_params)(x)\n",
        "        x = Activation('relu', name=relu_name + '2')(x)\n",
        "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "        x = Conv2D(filters, (3, 3), name=conv_name + '2', **conv_params)(x)\n",
        "\n",
        "        shortcut = Conv2D(filters, (1, 1), name=sc_name, strides=strides, **conv_params)(shortcut)\n",
        "        x = Add()([x, shortcut])\n",
        "        return x\n",
        "\n",
        "    return layer\n",
        "\n",
        "\n",
        "def usual_conv_block(filters, stage, block, strides=(2, 2)):\n",
        "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    \"\"\"\n",
        "\n",
        "    def layer(input_tensor):\n",
        "        conv_params = get_conv_params()\n",
        "        bn_params = get_bn_params()\n",
        "        conv_name, bn_name, relu_name, sc_name = handle_block_names(stage, block)\n",
        "\n",
        "        x = BatchNormalization(name=bn_name + '1', **bn_params)(input_tensor)\n",
        "        x = Activation('relu', name=relu_name + '1')(x)\n",
        "        shortcut = x\n",
        "        x = Conv2D(filters, (1, 1), name=conv_name + '1', **conv_params)(x)\n",
        "\n",
        "        x = BatchNormalization(name=bn_name + '2', **bn_params)(x)\n",
        "        x = Activation('relu', name=relu_name + '2')(x)\n",
        "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "        x = Conv2D(filters, (3, 3), strides=strides, name=conv_name + '2', **conv_params)(x)\n",
        "\n",
        "        x = BatchNormalization(name=bn_name + '3', **bn_params)(x)\n",
        "        x = Activation('relu', name=relu_name + '3')(x)\n",
        "        x = Conv2D(filters*4, (1, 1), name=conv_name + '3', **conv_params)(x)\n",
        "\n",
        "        shortcut = Conv2D(filters*4, (1, 1), name=sc_name, strides=strides, **conv_params)(shortcut)\n",
        "        x = Add()([x, shortcut])\n",
        "        return x\n",
        "\n",
        "    return layer\n",
        "\n",
        "\n",
        "def usual_identity_block(filters, stage, block):\n",
        "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
        "    # Arguments\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    \"\"\"\n",
        "\n",
        "    def layer(input_tensor):\n",
        "        conv_params = get_conv_params()\n",
        "        bn_params = get_bn_params()\n",
        "        conv_name, bn_name, relu_name, sc_name = handle_block_names(stage, block)\n",
        "\n",
        "        x = BatchNormalization(name=bn_name + '1', **bn_params)(input_tensor)\n",
        "        x = Activation('relu', name=relu_name + '1')(x)\n",
        "        x = Conv2D(filters, (1, 1), name=conv_name + '1', **conv_params)(x)\n",
        "\n",
        "        x = BatchNormalization(name=bn_name + '2', **bn_params)(x)\n",
        "        x = Activation('relu', name=relu_name + '2')(x)\n",
        "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "        x = Conv2D(filters, (3, 3), name=conv_name + '2', **conv_params)(x)\n",
        "\n",
        "        x = BatchNormalization(name=bn_name + '3', **bn_params)(x)\n",
        "        x = Activation('relu', name=relu_name + '3')(x)\n",
        "        x = Conv2D(filters*4, (1, 1), name=conv_name + '3', **conv_params)(x)\n",
        "\n",
        "        x = Add()([x, input_tensor])\n",
        "        return x\n",
        "\n",
        "    return layer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCK-QaqWSSce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import get_file\n",
        "\n",
        "def get_conv_params(**params):\n",
        "    default_conv_params = {\n",
        "        'kernel_initializer': 'glorot_uniform',\n",
        "        'use_bias': False,\n",
        "        'padding': 'valid',\n",
        "    }\n",
        "    default_conv_params.update(params)\n",
        "    return default_conv_params\n",
        "\n",
        "def get_bn_params(**params):\n",
        "    default_bn_params = {\n",
        "        'axis': 3,\n",
        "        'momentum': 0.99,\n",
        "        'epsilon': 2e-5,\n",
        "        'center': True,\n",
        "        'scale': True,\n",
        "    }\n",
        "    default_bn_params.update(params)\n",
        "    return default_bn_params\n",
        "\n",
        "\n",
        "def find_weights(weights_collection, model_name, dataset, include_top):\n",
        "    w = list(filter(lambda x: x['model'] == model_name, weights_collection))\n",
        "    w = list(filter(lambda x: x['dataset'] == dataset, w))\n",
        "    w = list(filter(lambda x: x['include_top'] == include_top, w))\n",
        "    return w\n",
        "\n",
        "\n",
        "def load_model_weights(weights_collection, model, dataset, classes, include_top):\n",
        "    weights = find_weights(weights_collection, model.name, dataset, include_top)\n",
        "\n",
        "    if weights:\n",
        "        weights = weights[0]\n",
        "\n",
        "        if include_top and weights['classes'] != classes:\n",
        "            raise ValueError('If using `weights` and `include_top`'\n",
        "                             ' as true, `classes` should be {}'.format(weights['classes']))\n",
        "\n",
        "        weights_path = get_file(weights['name'],\n",
        "                                weights['url'],\n",
        "                                cache_subdir='models',\n",
        "                                md5_hash=weights['md5'])\n",
        "\n",
        "        model.load_weights(weights_path)\n",
        "\n",
        "    else:\n",
        "        raise ValueError('There is no weights for such configuration: ' +\n",
        "                         'model = {}, dataset = {}, '.format(model.name, dataset) +\n",
        "                         'classes = {}, include_top = {}.'.format(classes, include_top))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJa062A2QshZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_collection = [\n",
        "    # ResNet34\n",
        "    {\n",
        "        'model': 'resnet34',\n",
        "        'dataset': 'imagenet',\n",
        "        'classes': 1000,\n",
        "        'include_top': True,\n",
        "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet34_imagenet_1000.h5',\n",
        "        'name': 'resnet34_imagenet_1000.h5',\n",
        "        'md5': '2ac8277412f65e5d047f255bcbd10383',\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'model': 'resnet34',\n",
        "        'dataset': 'imagenet',\n",
        "        'classes': 1000,\n",
        "        'include_top': False,\n",
        "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet34_imagenet_1000_no_top.h5',\n",
        "        'name': 'resnet34_imagenet_1000_no_top.h5',\n",
        "        'md5': '8caaa0ad39d927cb8ba5385bf945d582',\n",
        "    },\n",
        "]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M3h8K0DQ183",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ResNet34(input_shape, input_tensor=None, weights=None, classes=1000, include_top=True):\n",
        "    model = build_resnet(input_tensor=input_tensor,\n",
        "                         input_shape=input_shape,\n",
        "                         repetitions=(3, 4, 6, 3),\n",
        "                         classes=classes,\n",
        "                         include_top=False,\n",
        "                         block_type='basic')\n",
        "    model.name = 'resnet34'\n",
        "\n",
        "    if weights:\n",
        "        load_model_weights(weights_collection, model, weights, classes, include_top)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDREJUCNYq0p",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P7huT2uQ9FX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = ResNet34(input_shape=(101,101, 3), weights=\"imagenet\", classes=100, include_top=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhBjG3lIR-1f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e04043b-d21a-4ef3-ae37-9f0fe64c118a"
      },
      "source": [
        "kk = [layer for layer in base_model.layers]\n",
        "len(kk)    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "158"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E-X41o2V_wk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i, layer in enumerate(base_model.layers):\n",
        "#     print(i, layer.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2glQhtXNTF5Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b28b93cc-ecb2-489e-a6cc-93bfe3639447"
      },
      "source": [
        "base_model.get_layer(base_model.layers[70].name).output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'zero_padding2d_84/Pad:0' shape=(?, 15, 15, 128) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnYo1ulSWDSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x = base_model.get_layer(\"stage2_unit4_conv2\").output\n",
        "x = base_model.get_layer(base_model.layers[83].name).output\n",
        "# x = Conv2D(100, (2,2))(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# let's add a fully-connected layer\n",
        "# x = Dense(100, activation='relu')(x)\n",
        "# and a logistic layer -- let's say we have 100 classes\n",
        "predictions = Dense(100, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "for layer in base_model.layers[:71]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "model.compile(optimizer=SGD(0.01, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# train the model on the new data for a few epochs\n",
        "# model.fit_generator(...)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCU9KxK4RUOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# base_model.get_layer(base_model.layers[74].name).output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFMRwUSieGLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFdxmORhUZz2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d065d0b1-239d-440f-a431-5422f391e1d7"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_11\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "data (InputLayer)               (None, 101, 101, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bn_data (BatchNormalization)    (None, 101, 101, 3)  9           data[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_69 (ZeroPadding2 (None, 107, 107, 3)  0           bn_data[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv0 (Conv2D)                  (None, 51, 51, 64)   9408        zero_padding2d_69[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "bn0 (BatchNormalization)        (None, 51, 51, 64)   256         conv0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu0 (Activation)              (None, 51, 51, 64)   0           bn0[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_70 (ZeroPadding2 (None, 53, 53, 64)   0           relu0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pooling0 (MaxPooling2D)         (None, 26, 26, 64)   0           zero_padding2d_70[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_bn1 (BatchNormaliz (None, 26, 26, 64)   256         pooling0[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_relu1 (Activation) (None, 26, 26, 64)   0           stage1_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_71 (ZeroPadding2 (None, 28, 28, 64)   0           stage1_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_conv1 (Conv2D)     (None, 26, 26, 64)   36864       zero_padding2d_71[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_bn2 (BatchNormaliz (None, 26, 26, 64)   256         stage1_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_relu2 (Activation) (None, 26, 26, 64)   0           stage1_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_72 (ZeroPadding2 (None, 28, 28, 64)   0           stage1_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_conv2 (Conv2D)     (None, 26, 26, 64)   36864       zero_padding2d_72[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_sc (Conv2D)        (None, 26, 26, 64)   4096        stage1_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 26, 26, 64)   0           stage1_unit1_conv2[0][0]         \n",
            "                                                                 stage1_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_bn1 (BatchNormaliz (None, 26, 26, 64)   256         add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_relu1 (Activation) (None, 26, 26, 64)   0           stage1_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_73 (ZeroPadding2 (None, 28, 28, 64)   0           stage1_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_conv1 (Conv2D)     (None, 26, 26, 64)   36864       zero_padding2d_73[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_bn2 (BatchNormaliz (None, 26, 26, 64)   256         stage1_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_relu2 (Activation) (None, 26, 26, 64)   0           stage1_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_74 (ZeroPadding2 (None, 28, 28, 64)   0           stage1_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_conv2 (Conv2D)     (None, 26, 26, 64)   36864       zero_padding2d_74[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 26, 26, 64)   0           stage1_unit2_conv2[0][0]         \n",
            "                                                                 add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit3_bn1 (BatchNormaliz (None, 26, 26, 64)   256         add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit3_relu1 (Activation) (None, 26, 26, 64)   0           stage1_unit3_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_75 (ZeroPadding2 (None, 28, 28, 64)   0           stage1_unit3_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit3_conv1 (Conv2D)     (None, 26, 26, 64)   36864       zero_padding2d_75[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit3_bn2 (BatchNormaliz (None, 26, 26, 64)   256         stage1_unit3_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit3_relu2 (Activation) (None, 26, 26, 64)   0           stage1_unit3_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_76 (ZeroPadding2 (None, 28, 28, 64)   0           stage1_unit3_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit3_conv2 (Conv2D)     (None, 26, 26, 64)   36864       zero_padding2d_76[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 26, 26, 64)   0           stage1_unit3_conv2[0][0]         \n",
            "                                                                 add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_bn1 (BatchNormaliz (None, 26, 26, 64)   256         add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_relu1 (Activation) (None, 26, 26, 64)   0           stage2_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_77 (ZeroPadding2 (None, 28, 28, 64)   0           stage2_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_conv1 (Conv2D)     (None, 13, 13, 128)  73728       zero_padding2d_77[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_bn2 (BatchNormaliz (None, 13, 13, 128)  512         stage2_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_relu2 (Activation) (None, 13, 13, 128)  0           stage2_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_78 (ZeroPadding2 (None, 15, 15, 128)  0           stage2_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_conv2 (Conv2D)     (None, 13, 13, 128)  147456      zero_padding2d_78[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_sc (Conv2D)        (None, 13, 13, 128)  8192        stage2_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_36 (Add)                    (None, 13, 13, 128)  0           stage2_unit1_conv2[0][0]         \n",
            "                                                                 stage2_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_bn1 (BatchNormaliz (None, 13, 13, 128)  512         add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_relu1 (Activation) (None, 13, 13, 128)  0           stage2_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_79 (ZeroPadding2 (None, 15, 15, 128)  0           stage2_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_conv1 (Conv2D)     (None, 13, 13, 128)  147456      zero_padding2d_79[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_bn2 (BatchNormaliz (None, 13, 13, 128)  512         stage2_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_relu2 (Activation) (None, 13, 13, 128)  0           stage2_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_80 (ZeroPadding2 (None, 15, 15, 128)  0           stage2_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_conv2 (Conv2D)     (None, 13, 13, 128)  147456      zero_padding2d_80[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_37 (Add)                    (None, 13, 13, 128)  0           stage2_unit2_conv2[0][0]         \n",
            "                                                                 add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit3_bn1 (BatchNormaliz (None, 13, 13, 128)  512         add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit3_relu1 (Activation) (None, 13, 13, 128)  0           stage2_unit3_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_81 (ZeroPadding2 (None, 15, 15, 128)  0           stage2_unit3_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit3_conv1 (Conv2D)     (None, 13, 13, 128)  147456      zero_padding2d_81[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit3_bn2 (BatchNormaliz (None, 13, 13, 128)  512         stage2_unit3_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit3_relu2 (Activation) (None, 13, 13, 128)  0           stage2_unit3_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_82 (ZeroPadding2 (None, 15, 15, 128)  0           stage2_unit3_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit3_conv2 (Conv2D)     (None, 13, 13, 128)  147456      zero_padding2d_82[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_38 (Add)                    (None, 13, 13, 128)  0           stage2_unit3_conv2[0][0]         \n",
            "                                                                 add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit4_bn1 (BatchNormaliz (None, 13, 13, 128)  512         add_38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit4_relu1 (Activation) (None, 13, 13, 128)  0           stage2_unit4_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_83 (ZeroPadding2 (None, 15, 15, 128)  0           stage2_unit4_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit4_conv1 (Conv2D)     (None, 13, 13, 128)  147456      zero_padding2d_83[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit4_bn2 (BatchNormaliz (None, 13, 13, 128)  512         stage2_unit4_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit4_relu2 (Activation) (None, 13, 13, 128)  0           stage2_unit4_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_84 (ZeroPadding2 (None, 15, 15, 128)  0           stage2_unit4_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit4_conv2 (Conv2D)     (None, 13, 13, 128)  147456      zero_padding2d_84[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_39 (Add)                    (None, 13, 13, 128)  0           stage2_unit4_conv2[0][0]         \n",
            "                                                                 add_38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_bn1 (BatchNormaliz (None, 13, 13, 128)  512         add_39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_relu1 (Activation) (None, 13, 13, 128)  0           stage3_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_85 (ZeroPadding2 (None, 15, 15, 128)  0           stage3_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_conv1 (Conv2D)     (None, 7, 7, 256)    294912      zero_padding2d_85[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_bn2 (BatchNormaliz (None, 7, 7, 256)    1024        stage3_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_relu2 (Activation) (None, 7, 7, 256)    0           stage3_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_86 (ZeroPadding2 (None, 9, 9, 256)    0           stage3_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_conv2 (Conv2D)     (None, 7, 7, 256)    589824      zero_padding2d_86[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_sc (Conv2D)        (None, 7, 7, 256)    32768       stage3_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_40 (Add)                    (None, 7, 7, 256)    0           stage3_unit1_conv2[0][0]         \n",
            "                                                                 stage3_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_bn1 (BatchNormaliz (None, 7, 7, 256)    1024        add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_8 (Glo (None, 256)          0           stage3_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 100)          25700       global_average_pooling2d_8[0][0] \n",
            "==================================================================================================\n",
            "Total params: 2,300,205\n",
            "Trainable params: 1,091,940\n",
            "Non-trainable params: 1,208,265\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XljWNtdmaC0u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1abfef30-68ea-4bc1-f02f-70ad6014f863"
      },
      "source": [
        "from keras.datasets import cifar100\n",
        "import numpy as np\n",
        "import cv2\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "\n",
        "# x_train_mean = np.mean(x_train, axis=(0,1,2))\n",
        "# x_train_std = np.std(x_train, axis=(0,1,2))\n",
        "\n",
        "# x_test_mean = np.mean(x_test, axis=(0,1,2))\n",
        "# x_test_std = np.std(x_test, axis=(0,1,2))\n",
        "\n",
        "# x_train = x_train.astype('float32')\n",
        "# x_test = x_test.astype('float32')\n",
        "\n",
        "# x_train = np.asarray([(x - x_train_mean) / x_train_std for x in x_train ])\n",
        "# x_test = np.asarray([(x - x_test_mean) / x_test_std for x in x_test ])\n",
        "\n",
        "\n",
        "\n",
        "# train_mean = np.mean(x_train, axis=(0,1,2))\n",
        "# train_std = np.std(x_train, axis=(0,1,2))\n",
        "\n",
        "# normalize = lambda x: ((x - train_mean) / train_std).astype('float32') # todo: check here\n",
        "# pad4 = lambda x: np.pad(x, [(0, 0), (4, 4), (4, 4), (0, 0)], mode='reflect')\n",
        "\n",
        "from  skimage import transform\n",
        "new_shape = (101,101)\n",
        "print(\"strt\")\n",
        "x_train = np.asarray([cv2.resize(image, new_shape) for image in x_train])\n",
        "x_test = np.asarray([transform.resize(image, new_shape) for image in x_test])\n",
        "\n",
        "# x_train = normalize(pad4(x_train))\n",
        "# x_test = normalize(pad4(x_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "strt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzkMBX7Elufc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import tensorflow as tf\n",
        "# crop = lambda x : tf.image.random_flip_left_right(tf.random_crop(x, [50000,32, 32, 3]))\n",
        "# x_train = crop(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-eVQnu_YNQE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ffb774b-792d-43fe-c6b9-4a2d5f9861be"
      },
      "source": [
        "x_train[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUR2QruEV6tw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fvpj99KVmtf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x_train_mean = np.mean(x_train, axis=(0,1,2))\n",
        "# x_train_std = np.std(x_train, axis=(0,1,2))\n",
        "# print(x_train_mean, x_train_std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnwLA9iUVpxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x_test_mean = np.mean(x_test, axis=(0,1,2))\n",
        "# x_test_std = np.std(x_test, axis=(0,1,2))\n",
        "# print(x_test_mean, x_test_std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYzfpB-UaEVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_train, num_classes=100, dtype='float32')\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes=100, dtype='float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvPxtd_cVlui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cutout_proba = 0.2\n",
        "ssr_proba = 0.15\n",
        "strong_aug_proba = 0.05\n",
        "\n",
        "start_reg_ssr = 5\n",
        "end_reg_ssr = 24\n",
        "\n",
        "start_strong_aug = 3\n",
        "end_strong_aug = 12\n",
        "\n",
        "from albumentations import (\n",
        "    Compose, HorizontalFlip, Rotate,GaussNoise ,RandomCrop,\n",
        "    RandomBrightness, RandomContrast,OneOf,\n",
        "    ToFloat, ShiftScaleRotate,PadIfNeeded\n",
        ")\n",
        "\n",
        "from albumentations import (HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
        "                            Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
        "                            IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine,\n",
        "                            IAASharpen, IAAEmboss, Flip, OneOf, Compose, ChannelShuffle,RandomContrast, RandomCrop)\n",
        "\n",
        "import cv2\n",
        "\n",
        "\n",
        "def get_cutout_eraser(p=0.4, s_l=0.05, s_h=0.3, r_1=0.3, r_2=1/0.3, \n",
        "                      v_l=-1,v_h=1,\n",
        "                      max_erasures_per_image=1, pixel_level=False):\n",
        "    assert max_erasures_per_image >= 1\n",
        "\n",
        "    def eraser(input_img):\n",
        "#         print(input_img.shape)\n",
        "        img_h, img_w, img_c = input_img.shape\n",
        "        shape = input_img.shape\n",
        "        p_1 = np.random.rand()\n",
        "\n",
        "        if p_1 > p:\n",
        "            return input_img\n",
        "        mx = np.random.randint(1, max_erasures_per_image + 1)\n",
        "        for i in range(mx):\n",
        "            while True:\n",
        "                s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "                r = np.random.uniform(r_1, r_2)\n",
        "                w = int(np.sqrt(s / r))\n",
        "                h = int(np.sqrt(s * r))\n",
        "                left = np.random.randint(0, img_w)\n",
        "                top = np.random.randint(0, img_h)\n",
        "\n",
        "                if left + w <= img_w and top + h <= img_h:\n",
        "                    break\n",
        "\n",
        "            if pixel_level:\n",
        "                c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
        "            else:\n",
        "                c = np.mean(input_img, axis=(0,1))\n",
        "\n",
        "            input_img[top:top + h, left:left + w, :] = c\n",
        "        return input_img\n",
        "\n",
        "    return eraser\n",
        "\n",
        "\n",
        "# def multiple_aug(x, y):\n",
        "#     x = tf.image.random_flip_left_right(tf.random_crop(x, [32, 32, 3]))\n",
        "#     return (x, y)\n",
        "\n",
        "# data_aug = lambda x, y: multiple_aug(x, y)\n",
        "\n",
        "\n",
        "cutout_fn = get_cutout_eraser(p=0.5, pixel_level=True)\n",
        "\n",
        "def batch_cut(imgs):\n",
        "    imgs = cutout_fn(imgs)\n",
        "    return imgs\n",
        "\n",
        "\n",
        "ssr = ShiftScaleRotate(p=ssr_proba)\n",
        "rotate_one = lambda x: ssr(image=x)['image']\n",
        "\n",
        "def rotate(imgs):\n",
        "    for i,im in enumerate(imgs):\n",
        "        imgs[i] = rotate_one(im)\n",
        "    return imgs\n",
        "\n",
        "\n",
        "AUGMENTATIONS_FOR_TRAIN = Compose([GaussNoise(p=0.25),\n",
        "                      RandomContrast(limit=0.2, p=0.5),\n",
        "                      HorizontalFlip(p=0.5),\n",
        "                      RandomCrop(32,32,p=1.0),\n",
        "                      PadIfNeeded(32,32),\n",
        "                      RandomBrightness(limit=0.2, p=0.5),\n",
        "                      ShiftScaleRotate(shift_limit=0.052, scale_limit=0.1, \n",
        "                                       rotate_limit=0, border_mode=cv2.BORDER_REFLECT_101, p=0.8)],\n",
        "                     p=strong_aug_proba)\n",
        "\n",
        "\n",
        "mix_aug = lambda x: AUGMENTATIONS_FOR_TRAIN(image=x)['image']\n",
        "def other_augs(imgs):\n",
        "    imgs = mix_aug(imgs)\n",
        "    return imgs\n",
        "\n",
        "#Apply AUG\n",
        "def combined_aug(imgs):\n",
        "    imgs = np.copy(imgs)\n",
        "    imgs = rotate(imgs)\n",
        "    imgs = batch_cut(imgs)\n",
        "    # imgs = other_augs(imgs)\n",
        "    return imgs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EG2La_WafJp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "90a68ac0-32ea-4240-8848-d82ee0c28f3c"
      },
      "source": [
        "# performing data argumentation by training image generator\n",
        "dataAugmentaion = ImageDataGenerator(preprocessing_function = combined_aug)\n",
        "\n",
        "# training the model\n",
        "model.fit_generator(dataAugmentaion.flow(x_train, y_train, batch_size = 64),\n",
        "                    validation_data = (x_test, y_test), \n",
        "                    steps_per_epoch = len(x_train) // 64,\n",
        "                    epochs = 50,\n",
        "                    ) \n",
        "\n",
        "\n",
        "\n",
        "# model.fit(x_train, y_train, \n",
        "#           batch_size=None, \n",
        "#           epochs=100, \n",
        "#           verbose=1, \n",
        "#           callbacks=None, \n",
        "# #           validation_split=0.0, \n",
        "#           validation_data=(x_test, y_test), \n",
        "#           shuffle=True, \n",
        "#           use_multiprocessing=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "781/781 [==============================] - 44s 56ms/step - loss: 4.1246 - acc: 0.0942 - val_loss: 4.8398 - val_acc: 0.0100\n",
            "Epoch 2/50\n",
            "781/781 [==============================] - 41s 53ms/step - loss: 2.9772 - acc: 0.2679 - val_loss: 5.2011 - val_acc: 0.0100\n",
            "Epoch 3/50\n",
            "781/781 [==============================] - 42s 54ms/step - loss: 2.4448 - acc: 0.3648 - val_loss: 6.0034 - val_acc: 0.0097\n",
            "Epoch 4/50\n",
            "781/781 [==============================] - 41s 53ms/step - loss: 2.1741 - acc: 0.4228 - val_loss: 6.4674 - val_acc: 0.0100\n",
            "Epoch 5/50\n",
            "638/781 [=======================>......] - ETA: 6s - loss: 2.0091 - acc: 0.4595"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pxQSQED1VI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataAugmentaion = ImageDataGenerator(preprocessing_function = combined_aug)\n",
        "\n",
        "# training the model\n",
        "model.fit_generator(dataAugmentaion.flow(x_train, y_train, batch_size = 16),\n",
        "                    validation_data = (x_test, y_test), \n",
        "                    steps_per_epoch = len(x_train) // 32,\n",
        "                    epochs = 20,\n",
        "                    ) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g7zPYAa938O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f6TQo3z4Yjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataAugmentaion = ImageDataGenerator(preprocessing_function = combined_aug)\n",
        "\n",
        "# training the model\n",
        "model.fit_generator(dataAugmentaion.flow(x_train, y_train, batch_size = 32),\n",
        "                    validation_data = (x_test, y_test), \n",
        "                    steps_per_epoch = len(x_train) // 32,\n",
        "                    epochs = 40,\n",
        "                    ) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeQrM9S9afGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kk = model.evaluate(x_test, y_test)\n",
        "# scores = model.evaluate(X[test], Y[test], verbose=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLjXA7ZdafDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(kk)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vc-bLoXuafBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7DIOyjgYwCZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.layers[:155]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUuhXm-EY1Lf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}